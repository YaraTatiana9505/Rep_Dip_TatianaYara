{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# evaluate the mask rcnn model on the kangaroo dataset\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# class that defines and loads the kangaroo dataset\n",
    "class KangarooDataset(Dataset):\n",
    "\t# load the dataset definitions\n",
    "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
    "\t\t# define one class\n",
    "\t\tself.add_class(\"dataset\", 1, \"kangaroo\")\n",
    "\t\t# define data locations\n",
    "\t\timages_dir = dataset_dir + '/images/'\n",
    "\t\tannotations_dir = dataset_dir + '/annots/'\n",
    "\t\t# find all images\n",
    "\t\tfor filename in listdir(images_dir):\n",
    "\t\t\t# extract image id\n",
    "\t\t\timage_id = filename[:-4]\n",
    "\t\t\t# skip bad images\n",
    "\t\t\tif image_id in ['00090']:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images after 150 if we are building the train set\n",
    "\t\t\tif is_train and int(image_id) >= 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images before 150 if we are building the test/val set\n",
    "\t\t\tif not is_train and int(image_id) < 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\timg_path = images_dir + filename\n",
    "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
    "\t\t\t# add to dataset\n",
    "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
    "\n",
    "\t# extract bounding boxes from an annotation file\n",
    "\tdef extract_boxes(self, filename):\n",
    "\t\t# load and parse the file\n",
    "\t\ttree = ElementTree.parse(filename)\n",
    "\t\t# get the root of the document\n",
    "\t\troot = tree.getroot()\n",
    "\t\t# extract each bounding box\n",
    "\t\tboxes = list()\n",
    "\t\tfor box in root.findall('.//bndbox'):\n",
    "\t\t\txmin = int(box.find('xmin').text)\n",
    "\t\t\tymin = int(box.find('ymin').text)\n",
    "\t\t\txmax = int(box.find('xmax').text)\n",
    "\t\t\tymax = int(box.find('ymax').text)\n",
    "\t\t\tcoors = [xmin, ymin, xmax, ymax]\n",
    "\t\t\tboxes.append(coors)\n",
    "\t\t# extract image dimensions\n",
    "\t\twidth = int(root.find('.//size/width').text)\n",
    "\t\theight = int(root.find('.//size/height').text)\n",
    "\t\treturn boxes, width, height\n",
    "\n",
    "\t# load the masks for an image\n",
    "\tdef load_mask(self, image_id):\n",
    "\t\t# get details of image\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\t# define box file location\n",
    "\t\tpath = info['annotation']\n",
    "\t\t# load XML\n",
    "\t\tboxes, w, h = self.extract_boxes(path)\n",
    "\t\t# create one array for all masks, each on a different channel\n",
    "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "\t\t# create masks\n",
    "\t\tclass_ids = list()\n",
    "\t\tfor i in range(len(boxes)):\n",
    "\t\t\tbox = boxes[i]\n",
    "\t\t\trow_s, row_e = box[1], box[3]\n",
    "\t\t\tcol_s, col_e = box[0], box[2]\n",
    "\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
    "\t\t\tclass_ids.append(self.class_names.index('kangaroo'))\n",
    "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
    "\n",
    "\t# load an image reference\n",
    "\tdef image_reference(self, image_id):\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\treturn info['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define the prediction configuration\n",
    "class PredictionConfig(Config):\n",
    "\t# define the name of the configuration\n",
    "\tNAME = \"kangaroo_cfg\"\n",
    "\t# number of classes (background + kangaroo)\n",
    "\tNUM_CLASSES = 1 + 1\n",
    "\t# simplify GPU config\n",
    "\tGPU_COUNT = 1\n",
    "\tIMAGES_PER_GPU = 1\n",
    "\n",
    "# calculate the mAP for a model on a given dataset\n",
    "def evaluate_model(dataset, model, cfg):\n",
    "\tAPs = list()\n",
    "\tfor image_id in dataset.image_ids:\n",
    "\t\t# load image, bounding boxes and masks for the image id\n",
    "\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
    "\t\t# convert pixel values (e.g. center)\n",
    "\t\tscaled_image = mold_image(image, cfg)\n",
    "\t\t# convert image into one sample\n",
    "\t\tsample = expand_dims(scaled_image, 0)\n",
    "\t\t# make prediction\n",
    "\t\tyhat = model.detect(sample, verbose=0)\n",
    "\t\t# extract results for first sample\n",
    "\t\tr = yhat[0]\n",
    "\t\t# calculate statistics, including AP\n",
    "\t\tAP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "\t\t# store\n",
    "\t\tAPs.append(AP)\n",
    "\t# calculate the mean AP across all images\n",
    "\tmAP = mean(APs)\n",
    "\treturn mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 131\n",
      "Test: 32\n"
     ]
    }
   ],
   "source": [
    "# load the train dataset\n",
    "train_set = KangarooDataset()\n",
    "train_set.load_dataset('kangaroo', is_train=True)\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    "# load the test dataset\n",
    "test_set = KangarooDataset()\n",
    "test_set.load_dataset('kangaroo', is_train=False)\n",
    "test_set.prepare()\n",
    "print('Test: %d' % len(test_set.image_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\nexbas\\anaconda3\\envs\\tf_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\nexbas\\anaconda3\\envs\\tf_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\nexbas\\anaconda3\\envs\\tf_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\nexbas\\anaconda3\\envs\\tf_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1919: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\nexbas\\anaconda3\\envs\\tf_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\nexbas\\anaconda3\\envs\\tf_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\nexbas\\anaconda3\\envs\\tf_test\\lib\\site-packages\\mask_rcnn-2.1-py3.7.egg\\mrcnn\\model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\nexbas\\anaconda3\\envs\\tf_test\\lib\\site-packages\\mask_rcnn-2.1-py3.7.egg\\mrcnn\\model.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\users\\nexbas\\anaconda3\\envs\\tf_test\\lib\\site-packages\\mask_rcnn-2.1-py3.7.egg\\mrcnn\\model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From c:\\users\\nexbas\\anaconda3\\envs\\tf_test\\lib\\site-packages\\mask_rcnn-2.1-py3.7.egg\\mrcnn\\model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\nexbas\\anaconda3\\envs\\tf_test\\lib\\site-packages\\mask_rcnn-2.1-py3.7.egg\\mrcnn\\model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\nexbas\\anaconda3\\envs\\tf_test\\lib\\site-packages\\mask_rcnn-2.1-py3.7.egg\\mrcnn\\model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From c:\\users\\nexbas\\anaconda3\\envs\\tf_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\nexbas\\anaconda3\\envs\\tf_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\nexbas\\anaconda3\\envs\\tf_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\nexbas\\anaconda3\\envs\\tf_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\nexbas\\anaconda3\\envs\\tf_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\nexbas\\anaconda3\\envs\\tf_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create config\n",
    "cfg = PredictionConfig()\n",
    "# define the model\n",
    "model = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n",
    "# load model weights\n",
    "model.load_weights('mask_rcnn_kangaroo_cfg_0005.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mAP: 0.855\n",
      "Test mAP: 0.972\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on training dataset\n",
    "train_mAP = evaluate_model(train_set, model, cfg)\n",
    "print(\"Train mAP: %.3f\" % train_mAP)\n",
    "# evaluate model on test dataset\n",
    "test_mAP = evaluate_model(test_set, model, cfg)\n",
    "print(\"Test mAP: %.3f\" % test_mAP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
